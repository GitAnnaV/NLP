{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMittM3h4Uy9Z0jcaOgHTT9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install natasha"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oReX7hAHAxu5","executionInfo":{"status":"ok","timestamp":1741999987999,"user_tz":-600,"elapsed":2735,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}},"outputId":"86d00367-7318-4eb8-87ef-0bc5c8dfc346"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: natasha in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.9.1)\n","Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.5.0)\n","Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.10.0)\n","Requirement already satisfied: slovnet>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.6.0)\n","Requirement already satisfied: yargy>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.16.0)\n","Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.9.0)\n","Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.11/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from navec>=0.9.0->natasha) (1.26.4)\n","Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (0.7.2)\n","Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (0.6.2)\n","Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n"]}]},{"cell_type":"code","source":["from natasha import MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger, Doc"],"metadata":{"id":"yyBeP5v3A4rb","executionInfo":{"status":"ok","timestamp":1741999988002,"user_tz":-600,"elapsed":2,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["segmenter = Segmenter()\n","morph_vocab = MorphVocab()\n","emb = NewsEmbedding()\n","morph_tagger = NewsMorphTagger(emb)"],"metadata":{"id":"w4emCbMxA7u6","executionInfo":{"status":"ok","timestamp":1741999990378,"user_tz":-600,"elapsed":1213,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["text = \"Задача организации, в особенности же постоянное информационно-техническое обеспечение нашей деятельности требует определения и уточнения системы масштабного изменения ряда параметров. Практический опыт показывает, что начало повседневной работы по формированию позиции представляет собой интересный эксперимент проверки системы обучения кадров, соответствующей насущным потребностям! Задача организации, в особенности же дальнейшее развитие различных форм деятельности напрямую зависит от всесторонне сбалансированных нововведений?\""],"metadata":{"id":"h_9IT_enA9yu","executionInfo":{"status":"ok","timestamp":1741999990846,"user_tz":-600,"elapsed":23,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["1. Провести на любом тексте лемматизацию и стемминг (nltk, pymorphy2, pymorphy3, natasha)"],"metadata":{"id":"XzQRZw_jR2cr"}},{"cell_type":"code","source":["doc = Doc(text)\n","doc.segment(segmenter)\n","doc.tag_morph(morph_tagger)"],"metadata":{"id":"BMIcmwfaA_XB","executionInfo":{"status":"ok","timestamp":1741999992098,"user_tz":-600,"elapsed":9,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["for token in doc.tokens:\n","    token.lemmatize(morph_vocab)  # Лемматизация\n","    print(f\"Токен: {token.text}, Лемма: {token.lemma}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7K0aZ4zBdIF","executionInfo":{"status":"ok","timestamp":1741999993434,"user_tz":-600,"elapsed":56,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}},"outputId":"ddde5b08-1ad5-48d2-9b30-3039e57aae1c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Токен: Задача, Лемма: задача\n","Токен: организации, Лемма: организация\n","Токен: ,, Лемма: ,\n","Токен: в, Лемма: в\n","Токен: особенности, Лемма: особенность\n","Токен: же, Лемма: же\n","Токен: постоянное, Лемма: постоянный\n","Токен: информационно-техническое, Лемма: информационно-технический\n","Токен: обеспечение, Лемма: обеспечение\n","Токен: нашей, Лемма: наш\n","Токен: деятельности, Лемма: деятельность\n","Токен: требует, Лемма: требовать\n","Токен: определения, Лемма: определение\n","Токен: и, Лемма: и\n","Токен: уточнения, Лемма: уточнение\n","Токен: системы, Лемма: система\n","Токен: масштабного, Лемма: масштабный\n","Токен: изменения, Лемма: изменение\n","Токен: ряда, Лемма: ряд\n","Токен: параметров, Лемма: параметр\n","Токен: ., Лемма: .\n","Токен: Практический, Лемма: практический\n","Токен: опыт, Лемма: опыт\n","Токен: показывает, Лемма: показывать\n","Токен: ,, Лемма: ,\n","Токен: что, Лемма: что\n","Токен: начало, Лемма: начало\n","Токен: повседневной, Лемма: повседневный\n","Токен: работы, Лемма: работа\n","Токен: по, Лемма: по\n","Токен: формированию, Лемма: формирование\n","Токен: позиции, Лемма: позиция\n","Токен: представляет, Лемма: представлять\n","Токен: собой, Лемма: себя\n","Токен: интересный, Лемма: интересный\n","Токен: эксперимент, Лемма: эксперимент\n","Токен: проверки, Лемма: проверка\n","Токен: системы, Лемма: система\n","Токен: обучения, Лемма: обучение\n","Токен: кадров, Лемма: кадр\n","Токен: ,, Лемма: ,\n","Токен: соответствующей, Лемма: соответствовать\n","Токен: насущным, Лемма: насущный\n","Токен: потребностям, Лемма: потребность\n","Токен: !, Лемма: !\n","Токен: Задача, Лемма: задача\n","Токен: организации, Лемма: организация\n","Токен: ,, Лемма: ,\n","Токен: в, Лемма: в\n","Токен: особенности, Лемма: особенность\n","Токен: же, Лемма: же\n","Токен: дальнейшее, Лемма: дальнейший\n","Токен: развитие, Лемма: развитие\n","Токен: различных, Лемма: различный\n","Токен: форм, Лемма: форма\n","Токен: деятельности, Лемма: деятельность\n","Токен: напрямую, Лемма: напрямую\n","Токен: зависит, Лемма: зависеть\n","Токен: от, Лемма: от\n","Токен: всесторонне, Лемма: всесторонне\n","Токен: сбалансированных, Лемма: сбалансировать\n","Токен: нововведений, Лемма: нововведение\n","Токен: ?, Лемма: ?\n"]}]},{"cell_type":"code","source":["from nltk.stem.snowball import SnowballStemmer\n","\n","# Инициализация стеммера для русского языка\n","stemmer = SnowballStemmer(\"russian\")\n","\n","# Пример текста\n","text = \"Мама мыла раму, а потом пошла в магазин.\"\n","\n","# Токенизация (можно использовать Natasha или NLTK)\n","tokens = text.split()  # Простая токенизация по пробелам\n","\n","# Стемминг\n","for token in tokens:\n","    stem = stemmer.stem(token)\n","    print(f\"Токен: {token}, Стем: {stem}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CALQySpCDwo","executionInfo":{"status":"ok","timestamp":1741999996462,"user_tz":-600,"elapsed":56,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}},"outputId":"1f465ac2-32cc-467f-82cf-ad7950d2762f"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Токен: Мама, Стем: мам\n","Токен: мыла, Стем: мыл\n","Токен: раму,, Стем: раму,\n","Токен: а, Стем: а\n","Токен: потом, Стем: пот\n","Токен: пошла, Стем: пошл\n","Токен: в, Стем: в\n","Токен: магазин., Стем: магазин.\n"]}]},{"cell_type":"markdown","source":["2. Написать функцию для токенизации всех символов из ASCII"],"metadata":{"id":"G33lW2NFCJj_"}},{"cell_type":"code","source":["def tokenize(text: str) -> list[str]:\n","    \"\"\"\n","    Токенизирует текст на отдельные символы, оставляя только символы из ASCII.\n","\n","    :param text: Входная строка.\n","    :return: Список символов ASCII.\n","    \"\"\"\n","    return [char for char in text if ord(char) < 128]  # ASCII символы имеют код < 128\n","\n","# Пример использования\n","text = \"Hello, мир! 123\"\n","tokens = tokenize(text)\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIOXoIgJCKfJ","executionInfo":{"status":"ok","timestamp":1741999998280,"user_tz":-600,"elapsed":12,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}},"outputId":"e342f4d5-d36f-40ce-c92e-516ccc452e4e"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["['H', 'e', 'l', 'l', 'o', ',', ' ', '!', ' ', '1', '2', '3']\n"]}]},{"cell_type":"markdown","source":["3. Написать функцию для векторизации всех символов из ASCII"],"metadata":{"id":"r8TLoJQAC9x3"}},{"cell_type":"code","source":["def vectorize(tokens: list[str]) -> list[int]:\n","    return [sum(ord(char) for char in token) for token in tokens]\n","\n","# Пример использования\n","tokens = [\"Hello\", \"world\", \"123\", \"!!!\"]\n","vector = vectorize(tokens)\n","print(vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qoeWav4JC-yK","executionInfo":{"status":"ok","timestamp":1742000004131,"user_tz":-600,"elapsed":7,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}},"outputId":"6303fac8-0a1a-4e73-a777-d1ecbadd01cc"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["[500, 552, 150, 99]\n"]}]},{"cell_type":"markdown","source":["4. Провести токенизацию и векторизацию текста после лемматизации и стемминга"],"metadata":{"id":"xRKVJC6kESWb"}},{"cell_type":"code","source":["def tokenize(text: str) -> list[str]:\n","    return text.split()\n","\n","# Большой текст\n","text = \"\"\"\n","Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers\n","to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\"\n","the contents of documents, including the contextual nuances of the language within them. The technology can\n","then accurately extract information and insights contained in the documents as well as categorize and organize\n","the documents themselves.\n","\"\"\"\n","\n","# Токенизация текста\n","tokenized_text = tokenize(text)\n","print(\"Первые 5 токенов:\", tokenized_text[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zcgp8jNLFJz2","executionInfo":{"status":"ok","timestamp":1742000011765,"user_tz":-600,"elapsed":14,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}},"outputId":"f62fe8d1-d2af-4a86-eda9-aed54cf55c1d"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Первые 5 токенов: ['Natural', 'language', 'processing', '(NLP)', 'is']\n"]}]},{"cell_type":"code","source":["def vectorize(tokens: list[str]) -> list[int]:\n","    return [sum(ord(char) for char in token) for token in tokens]\n","vectorized_text = vectorize(tokenized_text)\n","print(\"Первые 5 векторов:\", vectorized_text[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GK9agNjZGzCB","executionInfo":{"status":"ok","timestamp":1742000019025,"user_tz":-600,"elapsed":11,"user":{"displayName":"Анна Вирасова","userId":"06657798546799114560"}},"outputId":"a1c4fcf2-ca67-46e8-fde6-27490babc75c"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Первые 5 векторов: [727, 836, 1085, 315, 220]\n"]}]}]}